---
title: 'Racial Steering by Large Language Models: A Prospective Audit of GPT-4 on Housing Recommendations'
layout: work
authors:
  - ericliu
  - wyso
  - peko
  - dignazio
year: 2024
date: 2024-10-24
doi: 10.1145/3689904.3694709
publisher: EAAMO '24
bibtex:
  type: article
  venue: proceedings
research_themes:
  - exposing
tags:
  - Peer-reviewed article
images:
  - figure_01.png
---
The integration of Large Language Models (LLMs) into a wide range of rental and real estate platforms could exacerbate historical inequalities in housing, particularly given that LLMs have exhibited gender, racial, ethnic, nationality, and language-based biases in other contexts. Examples of use cases already exist, with real estate listing platforms having launched ChatGPT plugins in 2023. In response to the critical need to assess the ways that LLMs may contribute to housing discrimination, we analyze GPT-4 housing recommendations in response to N = 168,000 prompts for renting and buying in the ten largest majority-minority cities in the US with prompts varying by demographic characteristics like sexuality, race, gender, family status, and source of income, many of which are protected under federal, state, and local fair housing laws. We find evidence of racial steering, default whiteness, and steering of minority homeseekers toward neighborhoods with lower opportunity indices in GPT-4â€™s housing recommendations to prospective buyers or renters, all of which could have the effect of exacerbating segregation in already segregated cities. Finally, we discuss potential legal implications on how LLMs could be liable under fair housing laws and end with policy recommendations regarding the importance of auditing, understanding, and mitigating risks from AI systems before they are put to use.